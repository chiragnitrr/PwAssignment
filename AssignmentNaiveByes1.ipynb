{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770f21d4-928a-42bc-af39-f47746f4e2b3",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e8a16-1baa-4263-bf18-707517b5794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : Bayes' theorem, named after the 18th-century statistician and philosopher Thomas Bayes, is a fundamental concept in\n",
    "probability theory and statistics. It provides a way to update our beliefs or probabilities about an event based on new evidence or\n",
    "information. Bayes' theorem is particularly useful in situations involving uncertainty and conditional probabilities. The theorem can \n",
    "be stated as follows:\n",
    "    P(A∣B) =( P(B∣A)⋅P(A) ) / P(B)\n",
    "    \n",
    "- P(A∣B) is the conditional probability of event A occurring given that event B has occurred. This is the probability we want to \n",
    "calculate based on new evidence.\n",
    "- P(B∣A) is the conditional probability of event B occurring given that event A has occurred. This represents our prior knowledge or\n",
    "beliefs about the relationship between events A and B.\n",
    "- P(A) is the probability of event A occurring independently of any other events. This is often referred to as the prior probability \n",
    "of A.\n",
    "- P(B) is the probability of event B occurring independently of any other events. This is often referred to as the prior probability \n",
    "of B.\n",
    "\n",
    "In words, Bayes' theorem tells us how to update our beliefs about the probability of event A given new evidence B. We do this by \n",
    "multiplying our prior belief in the relationship between A and B (expressed as P(B∣A)) by our prior belief in the probability of A \n",
    "(expressed as P(A)), and then dividing by the overall probability of B (expressed as P(B))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cfb4fc-0ff1-4b0e-86a0-bc37c030c87b",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69e9a2-7c0e-4d91-ac1e-1fd063f790f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer :  P(A∣B)= ( P(B∣A)⋅P(A) ) / P(B)\n",
    "    \n",
    "- P(A∣B) is the conditional probability of event A occurring given that event B has occurred. This is the probability we want to \n",
    "calculate based on new evidence.\n",
    "- P(B∣A) is the conditional probability of event B occurring given that event A has occurred. This represents our prior knowledge or\n",
    "beliefs about the relationship between events A and B.\n",
    "- P(A) is the probability of event A occurring independently of any other events. This is often referred to as the prior probability \n",
    "of A.\n",
    "- P(B) is the probability of event B occurring independently of any other events. This is often referred to as the prior probability \n",
    "of B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04edf54c-7383-4fb1-a7b2-880fe69dc680",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead11a0a-657d-45c4-94d7-a73e0bc21ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : Bayes' theorem is used in practice in a wide range of fields and applications to make informed decisions, update beliefs,\n",
    "and perform probabilistic reasoning. Here are some practical examples of how Bayes' theorem is used:\n",
    "\n",
    "1. Medical Diagnosis: Bayes' theorem is commonly used in medical diagnosis. Doctors can update the probability of a patient having a\n",
    "particular disease based on symptoms and test results. For example, if a patient has a certain set of symptoms (evidence B), Bayes'\n",
    "theorem can be used to update the probability of having a specific disease (event A).\n",
    "\n",
    "2. Spam Email Filtering: Spam filters in email services often use Bayesian classification. By analyzing the content and characteristics\n",
    "of emails (evidence B), the filter calculates the probability of an email being spam (event A). This helps in effectively sorting out \n",
    "unwanted emails.\n",
    "\n",
    "3. Machine Learning and Natural Language Processing: Bayesian methods are used in machine learning algorithms, such as Naive Bayes\n",
    "classifiers. These classifiers use Bayes' theorem to estimate the probability of a document or text belonging to a particular category\n",
    "based on the words or features in the document.\n",
    "\n",
    "4. Weather Forecasting: Bayes' theorem can be applied to update weather predictions as new data becomes available. Meteorologists can\n",
    "use past weather data, current conditions, and other relevant information (evidence B) to update their predictions about future \n",
    "weather events (event A).\n",
    "\n",
    "5. A/B Testing in Marketing: A/B testing is used to assess the effectiveness of marketing campaigns. Bayes' theorem can help calculate\n",
    "the probability that one version of a campaign (e.g., version A) is more effective than another (evidence B), given the observed \n",
    "outcomes (event A).\n",
    "\n",
    "6. Finance and Risk Management: Bayesian methods are used in financial modeling and risk assessment. For example, in portfolio \n",
    "management, Bayes' theorem can help investors update their beliefs about the performance of different assets based on new economic\n",
    "data (evidence B).\n",
    "\n",
    "7. Speech Recognition: In speech recognition systems, Bayes' theorem can be used to update the probabilities of different word\n",
    "sequences based on the observed audio input, improving the accuracy of transcription.\n",
    "\n",
    "8. Fault Diagnosis in Engineering: In industries like manufacturing and aerospace, Bayes' theorem can be used to diagnose faults or\n",
    "failures in complex systems by combining sensor data (evidence B) with prior knowledge of system behavior (event A).\n",
    "\n",
    "9. Crime Prediction and Law Enforcement: Bayes' theorem can be applied in predictive policing by analyzing historical crime data and\n",
    "updating the likelihood of future criminal activity in specific areas based on recent events (evidence B).\n",
    "\n",
    "10. Epidemiology and Disease Spread Modeling: In epidemiology, Bayes' theorem is used to update the estimates of disease transmission\n",
    "rates and the effectiveness of interventions based on new data and observations (evidence B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a75e6-fd39-40ae-a44f-48e5869e1ae7",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e36725-a1ca-416d-aef4-ea4bb9be2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : Bayes' theorem is closely related to conditional probability, and in fact, it provides a way to calculate conditional\n",
    "probabilities. Conditional probability is the probability of an event occurring given that another event has already occurred. Bayes' \n",
    "theorem allows us to update our beliefs about conditional probabilities based on new evidence.\n",
    "\n",
    "The relationship between Bayes' theorem and conditional probability can be understood through the following equation, which is one \n",
    "form of Bayes' theorem:\n",
    "P(A∣B)= ( P(B∣A)⋅P(A) ) / P(B)\n",
    "\n",
    "In this equation :\n",
    "- P(A∣B) represents the conditional probability of event A occurring given that event B has occurred. This is what we want to\n",
    "calculate.\n",
    "- P(B∣A) is the conditional probability of event B occurring given that event A has occurred. It represents our prior knowledge or \n",
    "belief about the relationship between A and B.\n",
    "- P(A) is the probability of event A occurring independently of any other events. It is the prior probability of A.\n",
    "- P(B) is the probability of event B occurring independently of any other events. It is the prior probability of B.\n",
    "\n",
    "Essentially, Bayes' theorem provides a way to update our prior belief (expressed as (P(A)) in the probability of event A based on new \n",
    "evidence or information (expressed as P(B∣A) and P(B)). It allows us to calculate the revised probability P(A∣B), which takes into\n",
    "account the relationship between events A and B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b73f5d-b925-4e0c-a9e7-d92395c0050b",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8232bcb-dea1-4fe3-b90f-95c8ef6e8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : Choosing the appropriate type of Naive Bayes classifier for a given problem depends on the nature of the data and the \n",
    "assumptions that can reasonably be made about the relationships between features (attributes). There are three main types of Naive \n",
    "Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's a general guideline for choosing \n",
    "the right one:\n",
    "\n",
    "1. Gaussian Naive Bayes (GNB):\n",
    "- Data Type: Continuous or real-valued data, where the features follow a Gaussian (normal) distribution.\n",
    "- Assumption: Assumes that the features within each class are normally distributed.\n",
    "- Examples: It's commonly used for problems involving real numbers, such as predicting the height of individuals based on other\n",
    "  features or classifying data with continuous attributes.\n",
    "\n",
    "2. Multinomial Naive Bayes (MNB):\n",
    "- Data Type: Discrete or count data, especially for text classification problems.\n",
    "- Assumption: Assumes that the features represent counts or frequencies of occurrences of discrete events.\n",
    "- Examples: Text classification tasks like spam detection, sentiment analysis, and document categorization, where the features often\n",
    "  represent word counts or term frequencies.\n",
    "\n",
    "3. Bernoulli Naive Bayes (BNB):\n",
    "- Data Type: Binary data, where each feature is binary (0 or 1).\n",
    "- Assumption: Assumes that features are binary-valued and that their probabilities follow a Bernoulli distribution.\n",
    "- Examples: Document classification tasks where the presence or absence of specific words or features in a document is the focus, \n",
    "  such as sentiment analysis or spam detection based on the presence or absence of certain keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc679ec2-4d2d-4931-b675-3e6c6e7f9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Assignment:\n",
    "    You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive \n",
    "    Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of \n",
    "    each feature value for each class:\n",
    "        Class\t X1=1    X1=2 \t  X1=3 \t  X2=1 \t  X2=2 \t  X2=3\t    X2=4\n",
    "         A\t       3\t 3\t        4\t    4\t    3\t    3\t      3\n",
    "         B\t       2\t 2\t        1\t    2\t    2       2\t      3\n",
    "    Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef3221-ebe6-499b-9ae7-afe61af0aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer :\n",
    "    To predict the class for a new instance with features X1 = 3 and X2 = 4 using Naive Bayes, you can calculate the conditional \n",
    "    probabilities for each class A and B and then choose the class with the highest probability. Given that you have equal prior\n",
    "    probabilities for each class (P(Class = A) = P(Class = B) = 0.5), you can use the Naive Bayes formula:\n",
    "\n",
    "P(Class | X1 = 3, X2 = 4) ∝ P(X1 = 3 | Class) * P(X2 = 4 | Class) * P(Class)\n",
    "\n",
    "Let's calculate the probabilities for both classes:\n",
    "\n",
    "For Class A:\n",
    "P(X1 = 3 | A) = 4/10\n",
    "P(X2 = 4 | A) = 3/10\n",
    "\n",
    "For Class B:\n",
    "P(X1 = 3 | B) = 1/9\n",
    "P(X2 = 4 | B) = 3/9\n",
    "\n",
    "Now, calculate the posterior probabilities for each class:\n",
    "\n",
    "For Class A:\n",
    "P(Class = A | X1 = 3, X2 = 4) ∝ (4/10) * (3/10) * 0.5 = 0.06\n",
    "\n",
    "For Class B:\n",
    "P(Class = B | X1 = 3, X2 = 4) ∝ (1/9) * (3/9) * 0.5 = 0.0185\n",
    "\n",
    "Since 0.06 > 0.0185, the Naive Bayes classifier would predict that the new instance with features X1 = 3 and X2 = 4 belongs to \n",
    "Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4fe66-5101-483a-a9a5-48d882dec9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
