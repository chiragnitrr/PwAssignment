{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d2cfe-05be-4db4-94e8-0a6f01ad333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Gradient Boosting Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b056b7-5d8d-43b3-b44d-24bd059e9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer :\n",
    "    \n",
    "Gradient Boosting Regression is a machine learning technique that belongs to the ensemble learning family. It is used for both\n",
    "classification and regression tasks. The basic idea behind gradient boosting is to combine multiple weak learners (usually decision \n",
    "trees) to create a strong predictive model.\n",
    "\n",
    "Here's a brief overview of how gradient boosting regression works:\n",
    "1. Base Learners (Weak Models): Gradient boosting starts with an initial simple model, often a shallow decision tree. This model is\n",
    "called a weak learner because it might not perform well on its own.\n",
    "\n",
    "2. Training Iteratively: The algorithm is trained iteratively. In each iteration, a new weak learner is added to the ensemble to \n",
    "correct the errors made by the existing ensemble. The new learner is trained on the residuals (the differences between the actual\n",
    "and predicted values) of the previous ensemble.\n",
    "\n",
    "3. Gradient Descent Optimization: The term \"gradient\" in gradient boosting refers to the use of gradient descent optimization to \n",
    "minimize the loss function. The algorithm minimizes the loss by moving in the direction of steepest decrease of the loss function \n",
    "with respect to the predictions.\n",
    "\n",
    "4. Combining Weak Models: The predictions from all weak learners are combined to form the final prediction. The final model is a \n",
    "weighted sum of the predictions from all the weak learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defed3a7-b238-4607-83a9-3060cfeae072",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a simple regression problem as an \n",
    "example and train the model on a small dataset. Evaluate the model's performance using metrics such as mean squared error and\n",
    "R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4346e5-0097-426b-b07b-5700f91cc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dfdbab-70f5-482c-b70c-698cf12847db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_regression(n_samples = 1000, n_features = 4, n_informative = 2, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0777773d-5cc5-4f30-8087-c0a6d4bd0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27652b3-5e86-4f36-89b4-a392be3cf99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12717d3-7baf-4fce-bf4d-ba31bac87510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ffd4d00-f708-4719-93e7-e3a61a668f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24da70af-07dd-43a9-b20e-829d9924296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44a73af-f637-4be3-b68c-de1707bbb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c6e06f-cc36-476a-b4e5-461a29b7a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7770980-c9e2-4a97-ae02-214a41ea8dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9935588768315411\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \" , r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8895ad-c056-4233-98f1-837147c0ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to optimise the performance of \n",
    "the model. Use grid search or random search to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "432049f4-f437-4870-8c8b-d871e07168d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc762b5-feab-4e32-8f11-9159ad709a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "               'learning_rate' : [0.01, 0.1, 1],\n",
    "                'max_depth' : [1,2,3],\n",
    "                'min_weight_fraction_leaf' : [0,0.1,0.2,0.3] }\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016dda13-3fad-4610-ba11-81540a0c5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43799d47-daea-4fc6-9742-612b500652ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(classifier2, param_grid = param_grid, refit = True, cv=5, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f67b8aec-4319-4050-9ea2-22f109d2d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0;, score=0.621 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0;, score=0.592 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0;, score=0.605 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0;, score=0.663 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.621 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.592 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.605 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.663 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.629 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.622 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.589 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.606 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.664 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.614 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.613 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.577 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.602 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.654 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0;, score=0.791 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.782 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.781 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.782 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.773 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.742 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.714 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.723 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.775 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.678 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.640 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.665 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.714 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0;, score=0.828 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0;, score=0.834 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0;, score=0.823 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0;, score=0.837 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.801 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.801 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.799 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.821 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.751 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.746 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.717 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.726 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.784 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.678 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.640 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.665 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.714 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0;, score=0.989 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0;, score=0.987 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0;, score=0.989 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.966 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.959 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.956 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.971 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.969 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.878 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.891 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.899 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.906 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.903 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.827 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.811 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.820 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.819 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0;, score=0.997 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0;, score=0.998 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0;, score=0.997 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0;, score=0.997 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0;, score=0.995 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.966 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.957 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.957 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.973 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.967 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.877 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.887 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.901 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.902 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.899 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.810 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.827 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.818 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.815 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0;, score=0.997 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0;, score=0.998 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0;, score=0.997 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0;, score=0.997 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0;, score=0.996 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.963 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.957 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.958 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.970 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.968 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.872 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.889 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.901 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.898 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.810 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.827 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.818 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.815 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0;, score=0.992 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0;, score=0.993 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0;, score=0.994 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0;, score=0.993 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0;, score=0.990 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.965 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.955 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.956 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.972 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.1;, score=0.961 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.871 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.884 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.902 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.2;, score=0.894 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.801 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.802 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=1, min_weight_fraction_leaf=0.3;, score=0.803 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0;, score=0.996 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0;, score=0.989 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0;, score=0.993 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0;, score=0.996 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0;, score=0.987 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.955 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.947 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.947 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.962 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.1;, score=0.951 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.862 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.872 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.888 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.890 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.2;, score=0.879 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.821 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.796 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.817 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.793 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=2, min_weight_fraction_leaf=0.3;, score=0.798 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0;, score=0.997 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0;, score=0.994 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0;, score=0.995 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0;, score=0.996 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0;, score=0.990 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.951 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.943 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.956 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.1;, score=0.946 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.852 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.870 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.887 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.883 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.2;, score=0.880 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.821 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.796 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.817 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.793 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_weight_fraction_leaf=0.3;, score=0.798 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0, 0.1, 0.2, 0.3]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0, 0.1, 0.2, 0.3]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
       "                         'max_depth': [1, 2, 3],\n",
       "                         'min_weight_fraction_leaf': [0, 0.1, 0.2, 0.3]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9fc502-6f0f-4bc4-97d9-f167407b7b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'min_weight_fraction_leaf': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcc946cb-50d0-424b-9ab8-1679ddc1f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0895659b-b4d6-46b0-88a6-b512e4fbf16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9938086841547614\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \" , r2_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849d3a1-cb9b-4e04-a95f-3351d4e9abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is a weak learner in Gradient Boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445c80d-6faf-4d20-9da9-e73dc3fc2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : In the context of gradient boosting, a weak learner refers to a model that performs slightly better than random chance on\n",
    "a given task. It is a model that is better than random guessing but may still make considerable errors. Weak learners are typically\n",
    "simple models, often shallow decision trees or linear models.\n",
    "\n",
    "The concept of using weak learners in ensemble methods like gradient boosting is based on the idea that by combining multiple weak\n",
    "learners, their individual weaknesses can be compensated for, leading to a strong and robust predictive model. Each weak learner is \n",
    "trained to focus on the mistakes or residuals of the combined model built in the previous iteration.\n",
    "\n",
    "In the context of gradient boosting regression:\n",
    "\n",
    "1. First Iteration: The initial weak learner is fit to the data, and its predictions are combined to form the initial ensemble.\n",
    "\n",
    "2. Subsequent Iterations: In each subsequent iteration, a new weak learner is added to the ensemble. This new learner is trained on\n",
    "the residuals (the differences between the actual and predicted values) of the current ensemble. The idea is to correct the errors \n",
    "made by the existing model.\n",
    "\n",
    "3. Cumulative Improvement: As more weak learners are added, the overall model becomes a strong learner capable of capturing complex \n",
    "patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6f6ba-301a-454d-b344-a16581873342",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the intuition behind the Gradient Boosting algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5958db2-9c21-4d3d-98ed-4825ffad9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : \n",
    "    The intuition behind the Gradient Boosting algorithm lies in the iterative improvement of a model's predictive performance by\n",
    "    sequentially combining weak learners. Here's a step-by-step intuition for understanding how Gradient Boosting works:\n",
    "\n",
    "Start with a Weak Model:\n",
    "\n",
    "Begin with a simple model, often a shallow decision tree, as the first weak learner.\n",
    "This initial model might perform poorly on the task but is better than random chance.\n",
    "\n",
    "Focus on Errors (Residuals):\n",
    "Identify the differences (residuals) between the actual target values and the predictions of the weak learner.\n",
    "These residuals represent the errors made by the current model.\n",
    "\n",
    "Train a New Model to Correct Errors:\n",
    "\n",
    "Train a new weak learner on the residuals of the previous model.\n",
    "The new model is tasked with capturing and correcting the errors made by the existing ensemble.\n",
    "Combine Models Additively:\n",
    "\n",
    "Combine the predictions of all weak learners additively.\n",
    "Each new model contributes to the overall prediction, with a weight determined by its performance in reducing the residuals.\n",
    "Gradient Descent Optimization:\n",
    "\n",
    "Use gradient descent optimization to find the direction in the feature space that minimizes the loss function.\n",
    "The algorithm iteratively moves towards the optimal direction, improving the model's performance.\n",
    "Iterative Refinement:\n",
    "\n",
    "Repeat the process iteratively, adding new weak learners to the ensemble in each iteration.\n",
    "Each new learner corrects the errors of the existing ensemble, gradually improving the model's accuracy.\n",
    "Stop at a Predetermined Number of Iterations or Criteria:\n",
    "\n",
    "The process continues until a specified number of weak learners are added or a certain criterion is met.\n",
    "Common criteria include achieving a satisfactory level of performance or avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574bb19-e01f-40e8-aad5-9edb408e2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da7a66-30b0-41e6-99a0-0255ab1b5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : \n",
    "    The Gradient Boosting algorithm builds an ensemble of weak learners in an iterative fashion. Here's a step-by-step explanation\n",
    "    of how the ensemble is constructed:\n",
    "\n",
    "1. Initialize with a Weak Learner:\n",
    "- The process starts with an initial weak learner, often a shallow decision tree.\n",
    "- The initial model is a simple approximation of the true relationship in the data.\n",
    "\n",
    "2. Calculate Residuals:\n",
    "- Calculate the residuals by finding the differences between the actual target values and the predictions of the current ensemble \n",
    "(which consists only of the initial weak learner in the first iteration).\n",
    "\n",
    "3. Train a New Weak Learner on Residuals:\n",
    "- Train a new weak learner (usually another decision tree) on the residuals.\n",
    "- The new learner's task is to capture and correct the errors made by the current ensemble.\n",
    "\n",
    "4. Compute Weighted Sum of Predictions:\n",
    "- Combine the predictions of all weak learners additively, with each learner's contribution weighted by a factor determined during\n",
    "training.\n",
    "- The weights are determined by an optimization algorithm, often using gradient descent.\n",
    "\n",
    "5. Update Residuals:\n",
    "- Calculate the residuals again, this time considering the combined predictions of the current ensemble.\n",
    "- These residuals represent the errors that the next weak learner will try to correct.\n",
    "\n",
    "6. Iterative Process:\n",
    "- Repeat steps 3 to 5 for a predetermined number of iterations or until a stopping criterion is met.\n",
    "- In each iteration, a new weak learner is trained to correct the errors of the current ensemble.\n",
    "\n",
    "7. Combine All Weak Learners:\n",
    "- The final prediction is the sum of the predictions from all weak learners, each weighted by its contribution to the overall model.\n",
    "- The combination of these weak learners results in a strong predictive model.\n",
    "\n",
    "8. Regularization (Optional):\n",
    "- Gradient Boosting algorithms may include regularization techniques to prevent overfitting. Regularization terms, such as \n",
    "shrinkage or depth constraints on trees, can be incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0169ed-e497-43f6-8e39-266353ca02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902d0f1-39ff-48a9-bf7e-56cd13272fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer :\n",
    "Constructing the mathematical intuition of the Gradient Boosting algorithm involves understanding the underlying principles of how \n",
    "the algorithm minimizes a loss function using gradient descent. Here are the steps involved in the mathematical intuition of Gradient\n",
    "Boosting:\n",
    "\n",
    "1. Define the Objective Function (Loss Function):\n",
    "Start with a loss function that measures the difference between the actual target values and the predicted values of the model.\n",
    "Common loss functions include mean squared error (for regression) or log loss (for classification).\n",
    "\n",
    "2. Initialize with a Simple Model:\n",
    "- Begin with an initial weak learner (often a shallow decision tree).\n",
    "- The initial model is a simple approximation of the true relationship, and its predictions are denoted as Fo(x) for the i-th \n",
    "obeservation.\n",
    "\n",
    "3. Compute Residuals:\n",
    "- Calculate the residuals by finding the differences between the actual target values(yi) and the predictions of the current model \n",
    "(Fm(x), where m is the iteration.)\n",
    "\n",
    "4. Train a New Weak Learner on Residuals:\n",
    "- Train a new weak learner to predict the residuals. The goal is to find a model, hm(x), that minimizes the loss when applied to the\n",
    "residuals (yi - Fm(x)).\n",
    "\n",
    "5. Update Model:\n",
    "- Update the model by adding the new weak learner's predictions to the current model:  Fm+1(x) = Fm(x) + α⋅hm(x).\n",
    "- The parameter α is the learning rate, controlling the step size in the gradient descent process.\n",
    "\n",
    "6. Compute New Residuals:\n",
    "- Calculate the new residuals based on the updated model: r_m+1 = yi - Fm+1(x). \n",
    "\n",
    "7. Iterative Process:\n",
    "- Repeat steps 4 to 6 for a predetermined number of iterations or until a stopping criterion is met.\n",
    "- In each iteration, a new weak learner is trained to predict the residuals, and its predictions are added to the current model.\n",
    "\n",
    "8. Final Model:\n",
    "- The final model is the sum of all weak learners : F(x) = Fo(x) + α⋅h1(x) + α⋅h2(x) + .... + α⋅hm(x).\n",
    "\n",
    "9. Regularization (Optional):\n",
    "- Regularization terms can be added to the objective function to prevent overfitting. For example, a regularization term might\n",
    "penalize complex models.\n",
    "\n",
    "10. Optimization (Gradient Descent):\n",
    "- The optimization process involves finding the best parameters (e.g., tree structure and leaf values) for each weak learner to\n",
    "minimize the overall loss function.\n",
    "- Gradient descent is used to update the parameters in the direction that minimizes the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08e8b1-8f72-4709-acf6-0f3d129ef036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
